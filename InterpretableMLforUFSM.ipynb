{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretable_MLmodel_urban_flood_susceptibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import cg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.tree \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import shap\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pylab as pl\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import math\n",
    "import torch\n",
    "# import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "# from interpret_community.tabular_explainer import TabularExplainer\n",
    "from captum.attr import IntegratedGradients\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "import time\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "# from interpret_community.tabular_explainer import TabularExplainer\n",
    "from captum.attr import IntegratedGradients\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "m=32\n",
    "random.seed(m)\n",
    "np.random.seed(m)\n",
    "torch.manual_seed(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_data_original=pd.read_csv('train_data_231017_两类事件.csv')\n",
    "test_data_original=pd.read_csv('test_data_231017_两类事件.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入特征归一化\n",
    "# 假设 train_data 是你的数据框\n",
    "scaler = MinMaxScaler()\n",
    "train_data = train_data_original.copy()  # 创建一个train_data的副本以保留原始数据\n",
    "train_data.iloc[:, 1:9] = scaler.fit_transform(train_data_original.iloc[:, 1:9])  # 归一化第一列到第12列的数据\n",
    "\n",
    "test_data = test_data_original.copy()  # 创建一个train_data的副本以保留原始数据\n",
    "test_data.iloc[:, 1:9] = scaler.fit_transform(test_data_original.iloc[:, 1:9])  # 归一化第一列到第12列的数据\n",
    "\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 class 列不同值及其个数\n",
    "class_counts = train_data['Suscept_3'].value_counts()\n",
    "print('label 列不同值及其个数为：\\n', class_counts)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看 class 列不同值及其个数\n",
    "class_counts = test_data['Suscept_3'].value_counts()\n",
    "print('suscept_3 列不同值及其个数为：\\n', class_counts)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将训练集和测试集合并起来\n",
    "data_train_test=pd.concat([train_data,test_data])\n",
    "df=data_train_test.iloc[:,1:-1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有特征\n",
    "\n",
    "all_features = df.iloc[:, :-1]\n",
    "\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集特征输入\n",
    "X_train = train_data.iloc[:,1:-1]\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_data['Suscept_3']\n",
    "\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.iloc[:,1:-2]\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = test_data['Suscept_3']\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "print(pd.value_counts(Y_train))\n",
    "\n",
    "print(pd.value_counts(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_test) == Y_test)/len(Y_test)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "\n",
    "def print_train_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_train) == Y_train)/len(Y_train)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "shap.initjs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入数据统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model_training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 定义XGBoost模型\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "    \n",
    "\n",
    "# 定义参数空间\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "}\n",
    "\n",
    "# 定义5折交叉验证策略\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 使用GridSearchCV进行自动调参和交叉验证\n",
    "grid_search_xgb = GridSearchCV(xgb_model,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='recall',\n",
    "                           cv=cv)\n",
    "\n",
    "grid_search_xgb.fit(X_train, Y_train)\n",
    "\n",
    "# 输出最优参数和最优得分\n",
    "print(\"Best parameters: \", grid_search_xgb.best_params_)\n",
    "print(\"Best score: \", grid_search_xgb.best_score_)\n",
    "\n",
    "# 用网格搜索到的最优参数重新训练模型\n",
    "params_xgb =grid_search_xgb.best_params_\n",
    "best_params_xgb = xgb.XGBClassifier(**params_xgb)\n",
    "best_params_xgb.fit(X_train, Y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xgb模型训练\n",
    "# 因为优化后之间训练模型就会在解释的时候，SHAP方法调用失败。因此，将优化好的参数重新训练模型\n",
    "# Best parameters:  {'colsample_bytree': 1, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.9}\n",
    "# Best score:  0.5849992669597436\n",
    "\n",
    "# Best parameters:  {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
    "# Best score:  0.8072517369212393\n",
    "# model_xgb = xgboost.XGBRegressor('colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8).fit(X_train, Y_train)\n",
    "# {'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
    "#Best score:  0.808133275323328\n",
    "# 'colsample_bytree': 1, 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.9\n",
    "# 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.9\n",
    "# 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8\n",
    "# Best parameters:  {'colsample_bytree': 1, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.9}\n",
    "\n",
    "# 231017:'colsample_bytree': 1, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.9\n",
    "# 231025:'colsample_bytree': 1, 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.9\n",
    "model_xgb_new = xgb.XGBClassifier(colsample_bytree=1, gamma= 0.2, learning_rate= 0.1, max_depth= 7, n_estimators= 200, subsample= 0.9)\n",
    "\n",
    "# train model on training set\n",
    "model_xgb_new.fit(X_train, Y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# nn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# 定义多层感知机模型\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    \n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
    "    #'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'max_iter': [100, 200, 500],\n",
    "    #'alpha': [0.0001, 0.05],\n",
    "    \n",
    "}\n",
    "\n",
    "# 定义5折交叉验证器\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True,random_state=42\n",
    ")\n",
    "\n",
    "# 定义网格搜索器\n",
    "grid_search_mlp = GridSearchCV(mlp, param_grid=param_grid,\n",
    "                           cv=cv, scoring='recall')\n",
    "\n",
    "# 训练模型并进行自动调参\n",
    "grid_search_mlp.fit(X_train, Y_train)\n",
    "\n",
    "# 输出最佳参数组合和对应的AUC值\n",
    "print('Best parameters:', grid_search_mlp.best_params_)\n",
    "print('Best AUC:', grid_search_mlp.best_score_)\n",
    "\n",
    "# 输出最优参数和最优得分\n",
    "print(\"Best parameters: \", grid_search_mlp.best_params_)\n",
    "print(\"Best score: \", grid_search_mlp.best_score_)\n",
    "\n",
    "# 用网格搜索到的nn最优参数重新训练模型\n",
    "\n",
    "params_mlp = grid_search_mlp.best_params_\n",
    "best_params_mlp = MLPClassifier(**params_mlp)\n",
    "best_params_mlp.fit(X_train, Y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nn\n",
    "# Best parameters: {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 500, 'solver': 'adam'}\n",
    "#Best parameters:  {'activation': 'logistic', 'hidden_layer_sizes': (50,), 'learning_rate': 'invscaling', 'max_iter': 200, 'solver': 'adam'}\n",
    "#Best score:  0.7586361913045934\n",
    "# 'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 500, 'solver': 'adam'\n",
    "# 'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 200, 'solver': 'adam'\n",
    "# 'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 500, 'solver': 'adam'\n",
    "\n",
    "# 231017:'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 200, 'solver': 'adam'\n",
    "# 231025:'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 500, 'solver': 'adam'\n",
    "model_mlp_new = MLPClassifier( activation= 'tanh', hidden_layer_sizes= (100,), learning_rate= 'constant', max_iter= 500, solver= 'adam')\n",
    "\n",
    "# train model on training set\n",
    "model_mlp_new.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# LR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "# 定义逻辑回归模型和参数网格\n",
    "lr = LogisticRegression()\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 500],\n",
    "}\n",
    "\n",
    "# 使用GridSearchCV进行自动调参和5折交叉验证\n",
    "grid_search_lr = GridSearchCV(lr, param_grid, scoring='recall', cv=cv)\n",
    "grid_search_lr.fit(X_train, Y_train)\n",
    "\n",
    "# 输出最优参数和最优得分\n",
    "print(\"Best parameters: \", grid_search_lr.best_params_)\n",
    "print(\"Best score: \", grid_search_lr.best_score_)\n",
    "\n",
    "# 重新训练模型\n",
    "params_lr = grid_search_lr.best_params_\n",
    "best_params_lr =  LogisticRegression(**params_lr)\n",
    "best_params_lr.fit(X_train, Y_train)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lr\n",
    "# 'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'\n",
    "#Best parameters:  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "# 'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'\n",
    "# 'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'\n",
    "# 'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'\n",
    "\n",
    "# 231017:'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear'\n",
    "# 231025:'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'\n",
    "model_lr_new = LogisticRegression(C= 10, max_iter= 100, penalty= 'l1', solver= 'liblinear')\n",
    "\n",
    "# train model on training set\n",
    "model_lr_new.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 定义随机森林模型\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# 定义交叉验证方法\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 定义网格搜索对象\n",
    "grid_search_rf = GridSearchCV(rf, param_grid, scoring='recall', cv=cv)\n",
    "\n",
    "# 训练模型并进行网格搜索\n",
    "grid_search_rf.fit(X_train, Y_train)\n",
    "\n",
    "# 输出最优参数和最优得分\n",
    "print(\"Best parameters: \", grid_search_rf.best_params_)\n",
    "print(\"Best score: \", grid_search_rf.best_score_)\n",
    "\n",
    "# 重新训练模型\n",
    "params_rf = grid_search_rf.best_params_\n",
    "best_params_rf =  RandomForestClassifier(**params_rf)\n",
    "best_params_rf.fit(X_train, Y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rf\n",
    "#Best parameters:  {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "# 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200\n",
    "# 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50\n",
    "# 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200\n",
    "\n",
    "# 231017:'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100\n",
    "# 231025:'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200\n",
    "model_rf_new = RandomForestClassifier(max_depth= 20, min_samples_leaf= 1, min_samples_split= 2, n_estimators= 200)\n",
    "\n",
    "# train model on training set\n",
    "model_rf_new.fit(X_train, Y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model_preformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将LR, XGB, NN的模型性能进行对比\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, auc\n",
    "\n",
    "# 训练三个机器学习模型并预测测试集\n",
    "\n",
    "model_lr = model_lr_new\n",
    "model_xgb =  model_xgb_new\n",
    "model_mlp =  model_mlp_new\n",
    "model_rf =  model_rf_new\n",
    "\n",
    "'''\n",
    "\n",
    "model_lr = best_params_lr\n",
    "model_xgb =  best_params_xgb\n",
    "model_mlp =  best_params_mlp\n",
    "model_rf =  best_params_rf\n",
    "'''\n",
    "\n",
    "\n",
    "Y_test_pred1 = model_lr.predict(X_test)\n",
    "Y_test_pred2 = model_xgb.predict(X_test)\n",
    "Y_test_pred3 = model_mlp.predict(X_test)\n",
    "Y_test_pred4 = model_rf.predict(X_test)\n",
    "\n",
    "# 计算评价指标\n",
    "accuracy_train1 = accuracy_score(Y_train, model_lr.predict(X_train))\n",
    "accuracy_train2 = accuracy_score(Y_train, model_xgb.predict(X_train))\n",
    "accuracy_train3 = accuracy_score(Y_train, model_mlp.predict(X_train))\n",
    "accuracy_train4 = accuracy_score(Y_train, model_rf.predict(X_train))\n",
    "\n",
    "accuracy_test1 = accuracy_score(Y_test, model_lr.predict(X_test))\n",
    "accuracy_test2 = accuracy_score(Y_test, model_xgb.predict(X_test))\n",
    "accuracy_test3 = accuracy_score(Y_test, model_mlp.predict(X_test))\n",
    "accuracy_test4 = accuracy_score(Y_test, model_rf.predict(X_test))\n",
    "\n",
    "precision_train1 = precision_score(Y_train, model_lr.predict(X_train))\n",
    "precision_train2 = precision_score(Y_train, model_xgb.predict(X_train))\n",
    "precision_train3 = precision_score(Y_train, model_mlp.predict(X_train))\n",
    "precision_train4 = precision_score(Y_train, model_rf.predict(X_train))\n",
    "\n",
    "precision_test1 = precision_score(Y_test, Y_test_pred1)\n",
    "precision_test2 = precision_score(Y_test, Y_test_pred2)\n",
    "precision_test3 = precision_score(Y_test, Y_test_pred3)\n",
    "precision_test4 = precision_score(Y_test, Y_test_pred4)\n",
    "\n",
    "recall_train1 = recall_score(Y_train, model_lr.predict(X_train))\n",
    "recall_train2 = recall_score(Y_train, model_xgb.predict(X_train))\n",
    "recall_train3 = recall_score(Y_train, model_mlp.predict(X_train))\n",
    "recall_train4 = recall_score(Y_train, model_rf.predict(X_train))\n",
    "\n",
    "recall_test1 = recall_score(Y_test, Y_test_pred1)\n",
    "recall_test2 = recall_score(Y_test, Y_test_pred2)\n",
    "recall_test3 = recall_score(Y_test, Y_test_pred3)\n",
    "recall_test4 = recall_score(Y_test, Y_test_pred4)\n",
    "\n",
    "f1score_train1 = f1_score(Y_train, model_lr.predict(X_train))\n",
    "f1score_train2 = f1_score(Y_train, model_xgb.predict(X_train))\n",
    "f1score_train3 = f1_score(Y_train, model_mlp.predict(X_train))\n",
    "f1score_train4 = f1_score(Y_train, model_rf.predict(X_train))\n",
    "\n",
    "f1score_test1 = f1_score(Y_test, Y_test_pred1)\n",
    "f1score_test2 = f1_score(Y_test, Y_test_pred2)\n",
    "f1score_test3 = f1_score(Y_test, Y_test_pred3)\n",
    "f1score_test4 = f1_score(Y_test, Y_test_pred4)\n",
    "\n",
    "# 将评价指标存储在字典中\n",
    "results_train = {\n",
    "    'Model': ['Model_lr', 'Model_xgb', 'Model_mlp'],\n",
    "    'Accuracy (train)': [accuracy_train1, accuracy_train2, accuracy_train3],\n",
    "    'Precision (train)': [precision_train1, precision_train2, precision_train3],\n",
    "    'Recall (train)': [recall_train1, recall_train2, recall_train3],\n",
    "    'F1 score (train)': [f1score_train1, f1score_train2, f1score_train3],\n",
    "}\n",
    "results_test = {\n",
    "    'Model': ['Model_lr', 'Model_xgb', 'Model_mlp'],\n",
    "    'Accuracy (test)': [accuracy_test1, accuracy_test2, accuracy_test3],\n",
    "    'Precision (test)': [precision_test1, precision_test2, precision_test3],\n",
    "    'Recall (test)': [recall_test1, recall_test2, recall_test3],\n",
    "    'F1 score (test)': [f1score_test1, f1score_test2, f1score_test3],\n",
    "}\n",
    "# 将字典转换为 Pandas 数据框\n",
    "df_results_train = pd.DataFrame(results_train)\n",
    "df_results_test = pd.DataFrame(results_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将评价指标存储在字典中\n",
    "results_train_rf = {\n",
    "    'Model': ['Model_lr', 'Model_xgb', 'Model_mlp','Model_rf'],\n",
    "    'Accuracy (train)': [accuracy_train1, accuracy_train2, accuracy_train3, accuracy_train4],\n",
    "    'Precision (train)': [precision_train1, precision_train2, precision_train3,precision_train4],\n",
    "    'Recall (train)': [recall_train1, recall_train2, recall_train3,recall_train4],\n",
    "    'F1 score (train)': [f1score_train1, f1score_train2, f1score_train3,f1score_train4],\n",
    "}\n",
    "results_test_rf = {\n",
    "    'Model': ['Model_lr', 'Model_xgb', 'Model_mlp','Model_rf'],\n",
    "    'Accuracy (test)': [accuracy_test1, accuracy_test2, accuracy_test3,accuracy_test4],\n",
    "    'Precision (test)': [precision_test1, precision_test2, precision_test3, precision_test4],\n",
    "    'Recall (test)': [recall_test1, recall_test2, recall_test3,recall_test4],\n",
    "    'F1 score (test)': [f1score_test1, f1score_test2, f1score_test3,f1score_test4],\n",
    "}\n",
    "# 将字典转换为 Pandas 数据框\n",
    "df_results_train_rf = pd.DataFrame(results_train_rf)\n",
    "df_results_test_rf = pd.DataFrame(results_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_train_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_test_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute performance metrics\n",
    "Y_test1 = Y_test.ravel() # 将Y_test1转换为一维数组\n",
    "xgb_loss = sklearn.metrics.log_loss(Y_test1, model_xgb.predict_proba(X_test)[:,1])\n",
    "linear_loss = sklearn.metrics.log_loss(Y_test1, model_lr.predict_proba(X_test)[:,1])\n",
    "nn_loss = sklearn.metrics.log_loss(Y_test1, model_mlp.predict_proba(X_test)[:,1])\n",
    "rf_loss = sklearn.metrics.log_loss(Y_test1, model_rf.predict_proba(X_test)[:,1])\n",
    "\n",
    "# constant_loss = sklearn.metrics.log_loss(Y_test1, np.zeros(len(Y_test1)) * y_strain.mean())\n",
    "print(\"XGBoost_loss\", xgb_loss)\n",
    "print(\"LR_loss\", linear_loss)\n",
    "print(\"MLP_loss\", nn_loss)\n",
    "print(\"RF_loss\", nn_loss)\n",
    "print()\n",
    "\n",
    "xgb_roc_auc = sklearn.metrics.roc_auc_score(Y_test1, model_xgb.predict_proba(X_test)[:,1])\n",
    "linear_roc_auc = sklearn.metrics.roc_auc_score(Y_test1, model_lr.predict_proba(X_test)[:,1])\n",
    "dnn_roc_auc = sklearn.metrics.roc_auc_score(Y_test1, model_mlp.predict_proba(X_test)[:,1])\n",
    "rf_roc_auc = sklearn.metrics.roc_auc_score(Y_test1, model_rf.predict_proba(X_test)[:,1])\n",
    "\n",
    "#svm_roc_auc = sklearn.metrics.roc_auc_score(Y_test1, svm_model.predict_proba(X_test))\n",
    "print(\"XGBoost_roc_auc\", xgb_roc_auc)\n",
    "print(\"LR_roc_auc\", linear_roc_auc)\n",
    "print(\"MLP_roc_auc\", dnn_roc_auc)\n",
    "print(\"RF_roc_auc\", rf_roc_auc)\n",
    "#print(\"svm_roc_auc\", svm_roc_auc)\n",
    "print()\n",
    "\n",
    "xgb_pr_auc = sklearn.metrics.average_precision_score(Y_test1, model_xgb.predict_proba(X_test)[:,1])\n",
    "linear_pr_auc = sklearn.metrics.average_precision_score(Y_test1, model_lr.predict_proba(X_test)[:,1])\n",
    "dnn_pr_auc = sklearn.metrics.average_precision_score(Y_test1, model_mlp.predict_proba(X_test)[:,1])\n",
    "rf_pr_auc = sklearn.metrics.average_precision_score(Y_test1, model_rf.predict_proba(X_test)[:,1])\n",
    "#svm_pr_auc = sklearn.metrics.average_precision_score(Y_test1, svm_model.predict_proba(X_test))\n",
    "print(\"XGBoost_pr_auc\", xgb_pr_auc)\n",
    "print(\"LR_pr_auc\", linear_pr_auc)\n",
    "print(\"MLP_pr_auc\", dnn_pr_auc)\n",
    "print(\"RF_pr_auc\", rf_pr_auc)\n",
    "#print(\"svm_pr_auc\", svm_pr_auc)\n",
    "print()\n",
    "\n",
    "xgb_fpr, xgb_tpr, thresholds = sklearn.metrics.roc_curve(Y_test1, model_xgb.predict_proba(X_test)[:,1])\n",
    "linear_fpr, linear_tpr, thresholds = sklearn.metrics.roc_curve(Y_test1, model_lr.predict_proba(X_test)[:,1])\n",
    "dnn_fpr, dnn_tpr, thresholds = sklearn.metrics.roc_curve(Y_test1, model_mlp.predict_proba(X_test)[:,1])\n",
    "rf_fpr, rf_tpr, thresholds = sklearn.metrics.roc_curve(Y_test1, model_rf.predict_proba(X_test)[:,1])\n",
    "#svm_fpr, svm_tpr, thresholds = sklearn.metrics.roc_curve(Y_test1, svm_model.predict_proba(X_test))\n",
    "\n",
    "\n",
    "#pl.plot(xgb_fpr, xgb_tpr, label=\"AUC XGBoost %.3f\" % xgb_roc_auc)\n",
    "pl.plot(rf_fpr, rf_tpr, label=\"AUC RF %.3f\" % rf_roc_auc)\n",
    "pl.plot(dnn_fpr, dnn_tpr, label=\"AUC MLP %.3f\" % dnn_roc_auc)\n",
    "pl.plot(linear_fpr, linear_tpr, label=\"AUC LR %.3f\" % linear_roc_auc)\n",
    "#pl.plot(svm_fpr, svm_tpr, label=\"SVM %f\" % svm_roc_auc)\n",
    "pl.legend()\n",
    "pl.title(\"ROC curves on test data\")\n",
    "pl.show()\n",
    "\n",
    "xgb_prec, xgb_recall, thresholds = sklearn.metrics.precision_recall_curve(Y_test1, model_xgb.predict_proba(X_test)[:,1])\n",
    "dnn_prec, dnn_recall, thresholds = sklearn.metrics.precision_recall_curve(Y_test1, model_mlp.predict_proba(X_test)[:,1])\n",
    "linear_prec, linear_recall, thresholds = sklearn.metrics.precision_recall_curve(Y_test1, model_lr.predict_proba(X_test)[:,1])\n",
    "rf_prec, rf_recall, thresholds = sklearn.metrics.precision_recall_curve(Y_test1, model_rf.predict_proba(X_test)[:,1])\n",
    "#svm_prec, svm_recall, thresholds = sklearn.metrics.precision_recall_curve(Y_test1, svm_model.predict_proba(X_test))\n",
    "\n",
    "# pl.plot(xgb_recall, xgb_prec, label=\"XGBoost %.3f\" % xgb_pr_auc)\n",
    "pl.plot(dnn_recall, dnn_prec, label=\"MLP %.3f\" % dnn_pr_auc)\n",
    "pl.plot(linear_recall, linear_prec, label=\"LR %.3f\" % linear_pr_auc)\n",
    "pl.plot(rf_recall, rf_prec, label=\"RF %.3f\" % rf_pr_auc)\n",
    "\n",
    "#pl.plot(svm_recall, svm_prec, label=\"SVM %f\" % svm_pr_auc)\n",
    "pl.legend()\n",
    "pl.title(\"Precision-Recall curves on test data\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将测试集的预测结果提取出来\n",
    "output_test_lr=pd.concat([test_data,pd.Series(model_lr.predict_proba(X_test)[:,1],name='probability_lr')], axis=1)\n",
    "output_test_xgb=pd.concat([test_data,pd.Series(model_xgb.predict_proba(X_test)[:,1],name='probability_xgb')], axis=1)\n",
    "output_test_mlp=pd.concat([test_data,pd.Series(model_mlp.predict_proba(X_test)[:,1],name='probability_mlp')], axis=1)\n",
    "output_test_rf=pd.concat([test_data,pd.Series(model_rf.predict_proba(X_test)[:,1],name='probability_rf')], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "output_test_lr.to_csv('output_test_lr.csv', index=False) \n",
    "output_test_xgb.to_csv('output_test_xgb.csv', index=False) \n",
    "output_test_mlp.to_csv('output_test_mlp.csv', index=False) \n",
    "output_test_rf.to_csv('output_test_rf.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reset_index(drop=True)\n",
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap-rf\n",
    "\n",
    "# 创建一个SHAP解释器\n",
    "explainer = shap.TreeExplainer(model_rf_new)\n",
    "\n",
    "# 计算测试集上的SHAP值\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# 将SHAP值转换为DataFrame\n",
    "# 对于二分类问题，shap_values通常是一个列表，其中包含每个类别的SHAP值\n",
    "# 我们通常关注正类的SHAP值，即shap_values[1]\n",
    "feature_important_rf = pd.DataFrame(shap_values[1], columns=X_test.columns)\n",
    "# 取绝对值\n",
    "# 将结果保存到CSV文件\n",
    "feature_important_rf.to_csv('feature_important_shap_rf_240328.csv', index=False)\n",
    "# 保存DataFrame到CSV文件（如果需要）\n",
    "feature_important_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们已经有了一个训练好的随机森林模型 `trained_rf_model`\n",
    "# 和一个测试集 `X_test`。\n",
    "\n",
    "# 创建LIME解释器\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),  # 使用训练数据的NumPy数组\n",
    "    feature_names=X_train.columns.tolist(),  # 特征名称列表\n",
    "    class_names=['Class 0', 'Class 1'],  # 类别名称\n",
    "    mode='classification'  # 分类模式\n",
    ")\n",
    "\n",
    "# 定义需要提取的特征列表\n",
    "str1 = [\"Max_1HR\", \"Max_1HR_2\", \"Max_1HR_72\", \"Max_1TD\", 'RH_Count', 'TD_Count', 'EV', 'TWI', 'DTW']\n",
    "\n",
    "# 初始化一个空的DataFrame来存储特征贡献度\n",
    "feature_importance_df = pd.DataFrame(columns=str1)\n",
    "\n",
    "# 对测试集中的每个样本应用LIME并提取特征贡献度\n",
    "for i in range(len(X_test)):\n",
    "    # 使用LIME解释器解释每个实例\n",
    "    exp = explainer.explain_instance(\n",
    "        X_test.iloc[i].values, \n",
    "        model_rf_new.predict_proba, \n",
    "        num_features=len(str1)\n",
    "    )\n",
    "    \n",
    "    # 提取特征贡献度并存入字典\n",
    "    feature_importance_scores = {feature: 0 for feature in str1}  # 初始化所有特征的贡献度为0\n",
    "    for feature, importance in exp.as_list():\n",
    "        for feature_name in str1:\n",
    "            if feature_name in feature:  # 检查特征名称是否存在于LIME返回的特征中\n",
    "                feature_importance_scores[feature_name] += importance  # 累加贡献度\n",
    "\n",
    "    # 将提取的特征贡献度添加到DataFrame中\n",
    "    feature_importance_df.loc[len(feature_importance_df)] = feature_importance_scores\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "feature_importance_df.to_csv('feature_important_lime_rf_240328.csv', index=False)\n",
    "\n",
    "# 打印DataFrame的前几行以检查结果\n",
    "print(feature_importance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime-lr\n",
    "X1_test=X_test\n",
    "X1_test_np=X1_test.to_numpy()\n",
    "\n",
    "# LIME——真\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X1_test_np ,class_names=['0', '1'], feature_names = X1_test.columns,\n",
    "                                                    verbose=False)\n",
    "\n",
    "# Create an empty DataFrame to store the feature importance scores\n",
    "feature_names = X1_test.columns\n",
    "feature_importance_df = pd.DataFrame(columns=feature_names)\n",
    "\n",
    "# Loop over each test sample\n",
    "for i in range(len(X1_test)):\n",
    "    # Get the test sample\n",
    "    test_sample = X1_test.iloc[i]\n",
    "    # Explain the test sample using LIME\n",
    "    exp = explainer.explain_instance(test_sample, model_lr_new.predict_proba, num_features=len(feature_names))\n",
    "    str1 = [\"Max_1HR\", \"Max_1HR_2\", \"Max_1HR_72\", \"Max_1TD\", 'RH_Count','TD_Count','EV','TWI','DTW']\n",
    "    dic = {}\n",
    "    for s in range(exp.as_list().__len__()): # range(exp.as_list().__len__())=7 是因为有7个特征，所以range(exp.as_list().__len__())=7\n",
    "        for i in str1:\n",
    "            if i in exp.as_list()[s][0]: # exp.as_list()[s][0]是特征名\n",
    "                dic[i] = exp.as_list()[s][1]\n",
    "    # feature_importance_scores = dict(exp.as_list())\n",
    "    feature_importance_scores = dic\n",
    "\n",
    "    # Get the feature importance scores\n",
    "    # feature_importance_scores = dict(exp.as_list())\n",
    "    # Add the feature importance scores to the DataFrame\n",
    "    feature_importance_df = pd.concat([feature_importance_df, pd.DataFrame([feature_importance_scores])], ignore_index=True)\n",
    "\n",
    "feature_importance_df.to_csv('feature_importance_scores_LIME_lr_240315.csv')\n",
    "print(feature_importance_df.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime-xgb\n",
    "X1_test=X_test\n",
    "X1_test_np=X1_test.to_numpy()\n",
    "\n",
    "# LIME——真\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X1_test_np ,class_names=['0', '1'], feature_names = X1_test.columns,\n",
    "                                                    verbose=False)\n",
    "\n",
    "# Create an empty DataFrame to store the feature importance scores\n",
    "feature_names = X1_test.columns\n",
    "feature_importance_df = pd.DataFrame(columns=feature_names)\n",
    "\n",
    "# Loop over each test sample\n",
    "for i in range(len(X1_test)):\n",
    "    # Get the test sample\n",
    "    test_sample = X1_test.iloc[i]\n",
    "    # Explain the test sample using LIME\n",
    "    exp = explainer.explain_instance(test_sample, model_xgb.predict_proba, num_features=len(feature_names))\n",
    "    str1 = [\"Max_1HR\", \"Max_1HR_2\", \"Max_1HR_72\", \"Max_1TD\",'RH_Count','TD_Count','EV','TWI','DTW']\n",
    "    dic = {}\n",
    "    for s in range(exp.as_list().__len__()): # range(exp.as_list().__len__())=7 是因为有7个特征，所以range(exp.as_list().__len__())=7\n",
    "        for i in str1:\n",
    "            if i in exp.as_list()[s][0]: # exp.as_list()[s][0]是特征名\n",
    "                dic[i] = exp.as_list()[s][1]\n",
    "    # feature_importance_scores = dict(exp.as_list())\n",
    "    feature_importance_scores = dic\n",
    "\n",
    "    # Get the feature importance scores\n",
    "    # feature_importance_scores = dict(exp.as_list())\n",
    "    # Add the feature importance scores to the DataFrame\n",
    "    feature_importance_df = pd.concat([feature_importance_df, pd.DataFrame([feature_importance_scores])], ignore_index=True)\n",
    "\n",
    "feature_importance_df.to_csv(feature_importance_scores_LIME_xgb_240315.csv')\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime-mlp\n",
    "X1_test=X_test\n",
    "X1_test_np=X1_test.to_numpy()\n",
    "\n",
    "# LIME——真\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X1_test_np ,class_names=['0', '1'], feature_names = X1_test.columns,\n",
    "                                                    verbose=False)\n",
    "\n",
    "# Create an empty DataFrame to store the feature importance scores\n",
    "feature_names = X1_test.columns\n",
    "feature_importance_df = pd.DataFrame(columns=feature_names)\n",
    "\n",
    "# Loop over each test sample\n",
    "for i in range(len(X1_test)):\n",
    "    # Get the test sample\n",
    "    test_sample = X1_test.iloc[i]\n",
    "    # Explain the test sample using LIME\n",
    "    exp = explainer.explain_instance(test_sample, model_mlp.predict_proba, num_features=len(feature_names))\n",
    "    str1 = [\"Max_1HR\",  \"Max_1HR_2\", \"Max_1HR_72\", \"Max_1TD\",'RH_Count','TD_Count','EV','TWI','DTW']\n",
    "    dic = {}\n",
    "    for s in range(exp.as_list().__len__()): # range(exp.as_list().__len__())=7 是因为有7个特征，所以range(exp.as_list().__len__())=7\n",
    "        for i in str1:\n",
    "            if i in exp.as_list()[s][0]: # exp.as_list()[s][0]是特征名\n",
    "                dic[i] = exp.as_list()[s][1]\n",
    "    # feature_importance_scores = dict(exp.as_list())\n",
    "    feature_importance_scores = dic\n",
    "\n",
    "    # Get the feature importance scores\n",
    "    # feature_importance_scores = dict(exp.as_list())\n",
    "    # Add the feature importance scores to the DataFrame\n",
    "    feature_importance_df = pd.concat([feature_importance_df, pd.DataFrame([feature_importance_scores])], ignore_index=True)\n",
    "\n",
    "feature_importance_df.to_csv('feature_importance_scores_LIME_mlp_240315.csv')\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap-lr\n",
    "\n",
    "# Load your trained model here, assuming it's stored in a variable called 'model'\n",
    "model = model_lr_new\n",
    "\n",
    "# Compute SHAP values for all test samples\n",
    "explainer = shap.Explainer(model, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Compute the sum of absolute SHAP values for each feature\n",
    "feature_importance = np.abs(shap_values.values).mean(0)\n",
    "feature_names = list(X_test.columns)\n",
    "\n",
    "# Sort the features by the sum of absolute SHAP values\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "sorted_features = [feature_names[i] for i in sorted_idx]\n",
    "\n",
    "# Create a DataFrame to store the feature rankings\n",
    "df = pd.DataFrame(columns=sorted_features)\n",
    "\n",
    "# Add each sample's feature rankings as a row in the DataFrame\n",
    "for i in range(X_test.shape[0]):\n",
    "    row = shap_values[i, sorted_idx].values.reshape(1, -1)\n",
    "    # 原来的代码\n",
    "    # df = df.append(pd.DataFrame(row, columns=sorted_features), ignore_index=True)\n",
    "\n",
    "    # 使用 pd.concat 替代\n",
    "    new_row = pd.DataFrame(row, columns=sorted_features)\n",
    "    df = pd.concat([df, new_row]).reset_index(drop=True)\n",
    "\n",
    "df_test_shap_lr = df\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "df_test_shap_lr.to_csv('feature_importance_scores_SHAP_lr_240315.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap-xgboost\n",
    "# 计算的是特征贡献值的绝对值\n",
    "\n",
    "# Compute SHAP values for all test samples.\n",
    "explainer = shap.Explainer(model_xgb_new)\n",
    "shap_values_11 = explainer(X_test)\n",
    "\n",
    "# Compute the sum of absolute SHAP values for each feature.\n",
    "shap_values_sum = np.abs(shap_values_11.values).sum(axis=0)\n",
    "\n",
    "feature_names = X_test.columns\n",
    "# Sort the features by the sum of absolute SHAP values.\n",
    "sorted_indices = np.argsort(shap_values_sum)[::-1]\n",
    "sorted_features = feature_names[sorted_indices]\n",
    "\n",
    "# Create a DataFrame to store the feature rankings.\n",
    "df_test_shap_xgb = pd.DataFrame(columns=sorted_features)\n",
    "\n",
    "# Add each sample's feature rankings as a row in the DataFrame.\n",
    "for i in range(len(X_test)):\n",
    "    row = np.abs(shap_values_11.values[i, sorted_indices]).tolist()\n",
    "    df_test_shap_xgb.loc[i] = row\n",
    "\n",
    "# Print the DataFrame.\n",
    "print(df_test_shap_xgb)\n",
    "# 将DF保存到CSV\n",
    "df_test_shap_xgb.to_csv('feature_importance_scores_SHAP_xgb_240315.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MLP model and test data\n",
    "mlp_model = model_mlp_new # load the MLP model\n",
    "\n",
    "\n",
    "# Calculate SHAP values for the test set using the MLP model.\n",
    "explainer = shap.Explainer(mlp_model.predict, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Compute the sum of absolute SHAP values for each feature.\n",
    "feature_importances = np.abs(shap_values.values).sum(axis=0)\n",
    "\n",
    "# Sort the feature importances for each sample.\n",
    "sorted_indices = np.argsort(-np.abs(shap_values.values), axis=1)\n",
    "\n",
    "# Create a DataFrame to store the feature importances.\n",
    "df_feature_importances = pd.DataFrame(columns=X_test.columns)\n",
    "\n",
    "# Add each sample's feature rankings as a row in the DataFrame.\n",
    "for i in range(len(X_test)):\n",
    "    row = np.abs(shap_values.values[i, sorted_indices[i]]).tolist()\n",
    "    df_feature_importances.loc[i] = row\n",
    "\n",
    "# Print the DataFrame.\n",
    "print(df_feature_importances)\n",
    "df_test_shap_mlp = df_feature_importances\n",
    "# 将DF保存到CSV\n",
    "df_test_shap_mlp.to_csv('feature_importance_scores_SHAP_mlp_240315.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
